# EEND-SS: JOINT END-TO-END NEURAL SPEAKER DIARIZATION AND SPEECH SEPARATION FOR FLEXIBLE NUMBER OF SPEAKERS

### Introduction

화자 분리(speaker diarization)와 음성 분리(speech separation)은 다양한 speech processing application에서 중요한 기술이다.
speaker diarization은 task는 어떠한 음성을 누가 언제 말했냐(who spoke when)는 것을 찾아내는 것이다. 
speech separation은 mixture된 input audio에서 각각의 화자를 분리(separation)하는 것이다. 
diarization의 정보를 안다면 separation에 도움이 되고 그 반대도 마찬가지(vice versa) 이지만 대부분의 경우 다른 정보를 미리 알수가 없다.

기존 clustering based system 에서는 동시에 여러 화자가 같은 시간에 말하지 않는 다는 것을 가정하므로 화자가 overlap된 데이터를 다룰 수 없고, end-to-end 모델 또한 아니다
초기의 end-to-end neural diarization(EEND)의 시스템은 overlap된 학습 데이터를 이용하여 훈련이 가능하지만 speaker의 수가 고정되어 있어야 한다
EEND-EDA는 EEND 모델에 LSTM encoder-decoder based attractor calculation을 사용하여 speaker의 수를 subtask로 count한다(overlap handling 가능)
EEND-SS(speaker diarization and separation) 시스템은 speech separation와 diarization를 서로의 성능을 더 좋게 하기위해 multi-task learning을 이용하여  하나의 네트워크에서 학습시켰다 
EEND-SS는 separation model로는 Conv-TasNet, diarization model로는 EEND-EDA를 사용한다
EEND-SS는 speech separation, speaker diarization, speaker counting의 3가지 error를 동시에 학습시킨다
또한 성능을 향상시키기 위해 2가지 방법을 추가로 적용했는데
여러명의 화자가 섞인 audio를 분리하기 위한 separation masks로 multiple 1x1 convolutional layer를 사용하며
speech activity로 학습된 diarization branch에서 speech를 separate하는 방법으로 사용한다




















