# SpEx+: A Complete Time Domain Speaker Extraction Network

## Introduction

화자 추출(speaker extraction)이란 muti-talker 환경에서 target speaker의 reference speech가 주어졌을 때,
target speech signal을 mixture에서 분리하는 작업이다

화자 추출은 target speaker의 reference speech를 이용하여 해결하는 task이다

화자 추출은 mixture speech에서 target speaker의 voice를 추출하므로 
mixture에 존재하는 speaker의 수를 알 필요가 없기 때문에 global permutation ambiguity problem이 발생하지 않는다

일반적인 화자 추출은 frequence-domain에서 수행되었으며 이 것은 signal reconstruction에서 발생하는 phase estimation issue가 존재한다

위 논문에선 phase estimation issue를 피하기 위해 time-domain에서 화자 특징을 추출하는 방법을 사용하였다

음성은 음소(phonemic), 운율(prosodic), 언어 내용(linguistic content) 등 다양한 정보를 가지고 있다

기존에 SpEx에서 사용한 speech encoder와 speaker encoder의 latent feature space의 mismatch를 해결하기 위해 같은 network 구조를 사용하고, weights를 공유하는 방법을 사용하였다

이러한 방법을 사용하면 mixture speech input과 reference speech input이 uniform한 latent feature space로 표현될 수 있다



## SpEx+ Architecture
SpEx+는 speech encoder, speaker encoder, speaker extractor, speech decoder로 구성되어 있다

기존 SpEx structure와 다른점은 speech encoder의 weights를 공유하고 있고, 이것을 twin speech encoders라고 명명한다

![image](https://github.com/kimho1wq/TIL/assets/15611500/390f493f-4797-4fa8-8d9c-070e58e6020e)


- (Twin) Speech encoder
  - input speech(mixture speech $y(t)$ or target speaker's reference speech $x(t)$)를 입력으로 받는다
  - speech encoder는 speaker encoding과 speech extraction의 두 가지 process로 진행되고, speaker encoding은 speech extraction에 도움을 주기 위한 speaker embedding을 출력한다 
  - 다양한 temporal resolutions을 추출하기 위해 다른 filter length의 1-D CNNs로 구성되어 있다
    - $Y = [Y_1, Y_2, Y_3] = e(\theta |y, L_1, L_2, L_3, N)$, $X = [X_1, X_2, X_3] = e(\theta |x, L_1, L_2, L_3, N)$
    - $e(\cdot)$은 twin speech encoder를 의미하고, $\theta$는 shared parameters, $L_1(short), L_2(middle), L_3(long)$은 각각 다른 length의 filter를 의미한다

- Speaker encoder
  - target speaker's reference speech의 speaker embedding을 추출하기 위해 사용된다
  - utterance-level speaker embedding $v$는 ResNet block을 거쳐 mean pooling operation을 이용하여 만들어 진다
    - $v = g(X), g(\cdot)$은 speaker encoder를 의미한다
    - ResNet의 구조: ![image](https://github.com/kimho1wq/TIL/assets/15611500/96f65c58-f3fe-4887-9cc6-408ed67302d8)
  - speaker encoder는 SpEx+ network의 sub-task로 볼 수 있고, speaker classification의 cross-entropy loss로 학습된다
  - speaker extraction에 적합한 speaker embedding을 추출하기 위해서 signal reconstruction loss를 사용하는 speaker extraction과 동시에 학습된다

- Speaker extractor, Speaker decoder
  - speaker extractor는 embedding coefficients $Y$와 speaker embedding $v$를 이용하여, 각각의 target speaker에 대한 mask $M_i$를 계산한다
  - mask $M_i$를 이용하여 $S_i = M_i \odot Y_i$를 element-wise mul로 계산하고, $S_i$를 speech decoder를 통해 time-domain signal인 $s_i(t)$로 reconstruction한다
  - Conv-TasNet과 유사하게 temporal convolutional network(TCN)의 $B=8$개의 block을 $R=4$번 반복하여 적용하였다
  - depth-wise separable convolution(De-CNN)에서 각 block마다 TCN의 dilation factor은 $w^b, (b \in (0, \cdots, B-1))$이다
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/81b6c2d7-4590-4ca6-a416-16109e32bd67)

- Multi-task learning
  - SpEx+는 high quality speech와 highly discriminative한 speaker embedding를 동시에 추출하는데 목표를 둔다
  - scale-invariant signal-to-distortion ration(SI-SDR) loss와 cross-entropy(CE) loss를 사용하여 multi-task learning을 수행한다
    - $L(\Theta | y,x,s,I) = L_{SI-SDR} + \gamma L_{CE}$
    - $y$는 input mixture speech, $x$는 reference speech of the target speaker, $s$는 target clean speech, $I$는 one-hot vector로 target speaker의 true class labels을 의미한다
    - $L_{SI-SDR}$는 signal reconstruction error를 최소화 하는 방향으로 정의된다
      - $L_{SI-SDR} = -[(1-\alpha-\beta) p(s_1, s) + \alphap(s_2, s) + \beta(s_3, s)]$
      - $p(\hat{s}, s) = 20\log_10\frac{||(\hat{s}^T s / s^T s) \odot s||}{||(\hat{s}^T s / s^T s) \odot s - \hat{s} ||}$
      - $\alpha$와 $\beta$는 weights이고, $\hat{s}$와 $s$는 각각 estimated signal과 target clean signal이고 s의 평균(mean)은 0으로 normalize되었다
    - $L_{CE}$는 speaker classification의 cross-entropy loss이다
      - $L_{CE} = -\displaystyle\sum_{i=1}^{N_s}{I_i\log(\sigma(W \odot v)_i)}$
      - $N_s$는 speaker의 개수이고, $I_i$는 true class label, $W$는 weight matrix, $\sigma(\odot)$은 softmax function, $\sigma(W \odot v)$는 예측 확률(predicted probability)를 의미한다


## Experiments and Discussion


















