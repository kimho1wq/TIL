# HM-CONFORMER: A CONFORMER-BASED AUDIO DEEPFAKE DETECTION SYSTEM WITH HIERARCHICAL POOLING AND MULTI-LEVEL CLASSIFICATION TOKEN AGGREGATION METHODS

## Introduction

딥러닝의 발전에 따라 VS(voice conversion)이나 TTS(text-to-speech)와 같은 system은 인간의 output(speech)와 구분할 수 없을 정도로 정교해 졌다

이러한 기술들의 발전으로 인해 deepfake 범죄나 spoofing attack에 사용될 수 있는 가능성이 있으므로 audio deepfake detection은 대책(countermeasuer, CM) 연구로써 가치가 있다

ADD(audio deepfake detection)은 voice conversion system에서 spoofed된 발성인지 진실된(bona-fide) 발성인지 spoofing attack을 검출하는 binary classification task이다

CM system의 연구는 frame level의 local features를 global features로 aggregation하는 방향으로 진행되었다

그리고 최근 연구에서 voice spoofing의 evidence로 unnatural emphasis와 intonation의 local level의 특징과 excessive smoothing의 global level의 특징이 존재 할 수 있다고 한다

이러한 관점으로 위 논문에서는 global features를 추출하는 transformer 구조 local features에 특화되어 있는 CNN이 결합된 의 conformer가 voice spoofing의 특징을 잘 추출할 것이라고 생각했다

게다가 local features를 추출하고 그 후에 global feature를 탐색하는 기존 시스템과 다르게, conformer는 local-global features를 동시에 고려한다는 장점이 있다

위 논문에서는 HM-Conformer 모델을 제안하였고, HM-Conformer는 기존 Conformer 구조에 hierarchical pooling과 multi-level classification token aggregation(MCA) 방법을 추가 적용하였다


## Related work
- Conformer
  - 기존 vanilla conformer는 ASR(automatic speech recognition)인 many-to-many task를 위해 디자인 되었기 때문에 frame-level feature들 사이의 중첩된 정보를 처리하는데 중점을 둔다
  - 반면 classification과 같은 many-to-one scenarios에서는 overlapping된 features보다 compact된 features를 전달하는 것이 더 이점이 있을것이라 가정하였다
  - 이러한 가정으로 인해 HM-conformer에서는 hierarchical pooling 방법을 적용하여 conformer block 사이에 down sampling layer를 추가하였다
  - 또한 hierarchical pooling 방법은 다양한 layer의 정보를 widely하게 인식하기 때문에 classification 성능 향상을 기대해 볼 수 있다
  - 추가적으로 다양한 encoder blocks에서 task-related 정보를 aggregation하기 위해 MCA 방법을 적용하였다
  - MCA 방법은 sequence의 token을 추출하는데 효과적인 CLS token을 이용하며, CLS token들은 task-related features를 추출하기 위해 각각 다른 classifier로 학습된다
  - Structure
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/0d5b9e53-b1b6-4352-a11e-6cc1fdd69a5a)
    - input을 tokenize하는 convolution sub-sampling과 linear layer가 있다
    - conv sub-sampling은 2 stride를 가지는 2D-conv layer로 frequency와 channel axes를 flatten하여 linear layer에 input되어 $h_0 \in R^{\frac{T}{2^n}\*d}$인 token이 출력된다
    - conformer block의 output $h_i$은 $h_{i-1}$이 FFN(feed forward network), MHSA(multi-head self-attention),  Conv(convolution module)의 순서대로 forward되어 출력된다
      - $\tilde{h}\_{i-1} = h\_{i-1} + \frac{1}{2}FFN(h\_{i-1})$
      - $\h^\prime\_{i-1} = \tilde{h}\_{i-1} + MHSA(\tilde{h}\_{i-1})$
      - $\h^{\prime\prime}\_{i-1} = \h^\prime\_{i-1} + Conv(\h^\prime\_{i-1})$
      - $h_i = LayerNorm(\h^{\prime\prime}\_{i-1} + \frac{1}{2}FFN(h^{\prime\prime}_{i-1}))$
    - $h_6 \in R^{\frac{T}{2^n} \* d}$은 SeqPooling을 거쳐 embedding $e$이 되고, $e$는 classifier $C$에 input되어 single scalar value인 $Score$를 출력한다
      - $e = wh_6 \in R^{1\*d}$, $w = softmax(linear(h_6)) \in R^{1\*\frac{T}{2^n}} $
      - $Score = C(e) = \sigma(eW^c_1 + b^c)W^c_2$
      - $W_1^c \in R^{d\*\frac{d}{2}}$, $W_2^c \in R^{\frac{d}{2}\*1}$, $b^c$는 학습 파라미터이고 $\sigma$는 $Swish$ activation function이다
      - Swish는 DeepNN에서 ReLU 보다 높은 정확도를 달성한다고 알려져 있고, 모든 $x < 0$ 에 대해 함수를 감소시키거나 증가시키지 않고 bounded below, unbounded above 특징을 갖는다
        - ![image](https://github.com/kimho1wq/TIL/assets/15611500/9bf218c9-e43c-43ff-978f-06b0925af5a1)


## Proposed system
![image](https://github.com/kimho1wq/TIL/assets/15611500/345cf223-c1e2-4531-9507-046ea2ba78ab)

- Hierarchical pooling method
  - 기존 Transformer 기반 구조 내의 token은 encoder가 진행됨에 따라 서로 유사해지려는 경향이 있다는 연구 결과가 있었다
  - 그에 따른 후속 연구로 classification과 같은 many-to-one task에서는 duplicate된 정보 보다 compact된 정보를 전달하는 것이 더 효과적이라는 결과가 있었다
  - 이러한 연구 내용을 바탕으로 Conformer block에서 compact 정보를 점진적으로 추출하는 방법을 사용하였다
  - tokens의 sequence length를 줄여감에 따라 더 집약적인 features를 추출할 수 있고, computational cost를 줄일 수 있다는 장점이 있다
  - Conformer block의 $h_i (i in (2,4))$에서만 pooling을 진행한다
    - $\hat{h}_i = pooling(h\_i; \gamma)$, $\gamma$는 down-sampling rate를 의미한다
    - 논문에서는 $\gamma=2$로 고정하였으며, $h_i \in R{T\prime \* d}$, $\hat{h}_i \in R^{\frac{T\prime}{\gamma} \* d}$가 된다
- Multi-level lassification token aggregation method
  - 다양한 layer의 multi-level feature aggregation은 classfication task의 성능을 향상시켜 준다는 연구가 존재한다
  - 하지만 Transformer의 lower layer는 task-relevant한 정보가 관찰되는 특징이 있다
  - 그래서 이러한 task-relevant한 정보를 CLS token과 같이 별도의 layer로 aggregation하여 task-related한 정보로 학습시키는 MCA 방법을 제안하였다
  - CLS token
    - token sequence의 시작 부분에 존재하는 학습 가능한 vector이며, MHSA module을 통해 sequence의 aggregated된 representation이다
    - CLS token은 classification task에서 주로 사용되는데 MCA method는 input sequence 뿐만 아니라, Conformer block(stage)에 입력된다
  - MCA methods와 hierarchical pooling은 같이 적용된다
    - input token sequence $h_0 = (cls_1, cls_2, cls_3, t_1, \cdots, t_{\frac{T}{2^n}}$이며 CLS token은 random하게 초기화된다
    - $t_i \in R^d$는 input tokens이고, $cls_i \in R^d$는 각 stage의 CLS tokens이다
    - Conformer block을 통과한 CLS tokens은 pooling layer에 입력되기 전에 분리되어 별도의 Linear layer에 입력되고, embedding을 출력하여 classifier로 학습한다
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/e55d8bdc-9d2d-40e9-8795-cd7bd2f8eff8)
      - 최종적으로 만들어지는 global-level embedding $e_5$는 $e_5 = flatten(e_1, \cdots, e_3, g) \odot W_4 + b_4$이다
      - $g = SeqPool(h_6[1:])$이며, global-level token이라 부르며, inference에서는 $e_5$의 embedding에서 출력된 $Score_5$만을 사용한다
    - CLS tokens, global-level token, and final embedding은 각각의 classifier로 전달되며 OC-Softmax loss $(L_{os})$로 학습된다
      - $Score_k = C_k(e_k) = \sigma(e_kW^k_1 + b^k)W^k_2$
      - $L_{os_k} = \frac{1}{N}\displaystyle\sum_{j=1}^N(1+exp^{\alpha(m_{y_j}-\hat{w_k}Score_k)(-1)^{y_j}})$
      - $L = \displaystyle\sum_{k=1}^5 w_kL_{oc_k}(Score_k)$
      - $\hat{w}_k$는 trainable single 파라미터, $\alpha$는 scale factor, $m\_{y\_j}$는 margins
      - $y_j$는 label을 의미하고 $y_j=0$은 bona-fide(진실), $y_j=1$은 spoofed(거짓)를 의미한다


## Experimental setup
- Datasets and evaluation metric
  - training and development: ASVspoof 2019 logical access task datasets
    - 5128 bona-fide, 45096 spoof utterances generated by six spoofing attack algorithms
  - evaluation: eval partitions of ASVspoof 2021 deepfake(DF) task datasets
    - 611829 samples fo 100 spoofed and bona-fide utterances combinations















