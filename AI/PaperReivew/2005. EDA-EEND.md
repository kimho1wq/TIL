# End-to-End Speaker Diarization for an Unknown Number of Speakers with Encoder-Decoder Based Attractors


## Introduction

기존 SA-EEND의 flexible 하지 못한 한계점을 encoder-decoder based attractor(EDA) calculation으로 해결하기 위한 방법

SA-EEND의 마지막 Fully-Connected layer의 weight (S x D, S: max number of speaker, D: hidden dim)를 사용한다면 test시에도 학습된 고정된 speaker attractor (weight)를 사용하여 최적의 speaker attractor가 아닐 수도 있다

network structure에 따라 maximum speaker의 수가 정해져 있다면, 실제 사용하는 inference에서 cluster의 한계가 정해지게 된다
 
또한 SA-EEND는 3명 이상인 경우, x-vector 보다 성능이 좋지 않음(여러 명의 경우 Relation information 을 잘 해석하지 못함)

기존의 고정된 화자 수와 weight 값 형태로 고정되어 있던 speaker attractor를 LSTM 기반 EDA로 부터 추출하여 사용하는 방법

EDA는 speech embedding sequences와 multiple attractors를 dot products를 사용하여 같은 수의 speaker activites를 생성한다

EEND에서 나온 SAD 결과만을 사용하는 것이 아닌, SAD 만을 담당하는 모듈로 부터 나온 결과를 이용한 후 처리 알고리즘을 제안

EEND-EDA도 여전히 학습되지 않은 화자 수에 경우 찾지 못하는 단점을 가지고 있기 때문에
Iterative inference 라는 방법을 이용해 많은 화자수가 존재하는 경우에 찾아내는 방법을 제안함


## Proposed method

### Encoder-decoder based attractor calculation
![image](https://github.com/kimho1wq/TIL/assets/15611500/48bb7947-d0a1-46bd-aa80-e9c9389fb784)

기본적으로 SA-EEND의 Encoder Block을 앞단에 동일하게 사용하여 embedding을 출력하고,
SA-EEND에서 사용하던 마지막 Linear 대신에 이를 LSTM 기반 Encoder-Decoder Attractor(EDA)의 출력 Attractor를 이용한다

EDA는 SA-EEND에서 생성한 Embedding 의 상태를 살펴보고, 이에 맞는 적절한(가변적인) 화자 수와 Speaker Attractor vector를 생성하여 처리한다


- Input: raw input -> T x 345 (23 log-mel x 15 (context length, near 7 frame))
  - STFT: window size: 25ms, hop size: 10ms
  - log-mel: 23 log-mel
  - Stacked Frame and Sub-Sampling: context length: 7, step size: 10, so, one frame sampled 10fps (1초에 10개 Frame 생성)0) Input: raw input -> T x 345 (23 log-mel x 15 (context length, near 7 frame))

- SA-EEND block: T x 345 -> T x 256
  - FC layer: T x 345 -> T x 256 (Transformer 입력을 위한 embedding 과정)
  - Encoder Block: (Self-Attention) T x 256 -> T x D(256) (Transformer로 Frame 별 Audio Feature Encoding)
  - 그 다음 $D$ 차원의 embedding $e_t$를 unidirectional LSTM encoder에 입력한다
  - $E = SA-EEND(x) = [e_1, \cdots, e_T] \in R^{D\*T} $

- Encoder-Decoder Attractor
  - Encoder (LSTM): T x 256 -> H(1 x 256), C(1 x 256)
    - $h_0, c_0 = Encoder(E)$, $h_0$과 $c_0$는 각각 마지막 hidden state와 cell state이다
    - SA-EEND block에서 생성된 embedding을 encoder 하는 과정이다.
    - 본 실험에서는 embedding을 LSTM에 넣을때, 시간 순서대로 넣은 방법(Sequential)과 무작위로 섞는 방법(Ramdom)으로 넣는 2가지 방법을 실험했다실험 결과는 Random이 좋았다.
    - 이 LSTM에서 생성된 H(Hidden State)와 C(Cell) 정보를 Decoder에 입력으로 전달한다.
  - Decoder(LSTM): H(1 x 256), C(1 x 256), Z(1 x 256) -> (1 x 256)
    - $h_s, c_s, a_s = Decoder(h_{s-1}, c_{s-1}, 0)$
    - $A = [a_1, \cdots, a_S] \in R^{D\*S}$
    - Encoder 로 부터 Hidden state 와 Cell 정보를 가져오며, input으로 는 1 x 256의 zero vector($0$)을 입력으로 받는다.
    - 이에 대해서 한 명의 Speaker 을 대표하는 1 x 256 크기의 Speaker Attractor를 생성한다.
  - Speaker Exists Decider (FC layer + Sigmoid): 1 x 256 -> 1 x 1
    - $p_s = \frac{1}{1+exp(-(w^Ta_s + b))}$, ($w, b$는 각각 fully-connected layer의 weight와 bias이다)
    - attractor $a_s$가 더 존재하는지 안하는지 결정하는 방법으로 여기서는 EDA를 jointly 하게 학습하기 위한 추가적인 Auxiliary loss를 사용한다.
      - 기존의 loss는 모든 hidden state를 다 거친 다음에 적용되는데 auxiliary loss 방식은 각각 hidden 개별 레이어에 대한 loss를 적용하는 방식
    - 이 attractor existence loss 는 EDA가 화자의 수를 정확하게 예측 하였는지에 대해서 평가한다.
      - $L_a = \frac{1}{1+S} BCE(l, p)$, $p = [p_1, \cdots, p_{s+1}]^T$
    - FC의 Layer의 결과가 일정 임계치(threshold) 값 이상인 경우 $1$ 아닌 경우 $0$으로 정한다.
      - $l_s = 1 (s \in 1,\cdots, S) or 0 (s = S+1)$
      - $1$: 추가적인 Speaker 가 존재함을 나타낸다.
      - $0$: Silence Speaker를 나타내며, Stop Criteria 로 LSTM Decoding 작업을 중지한다.
    - 여기서 FC layer의 결과가 0 이 나올때 까지 생성된 Attractor의 수가 S개라고 한다면, S-1는 EDA가 예측한(estimated) Embedding내 화자의 수이다.
    - inference phase에서 만약 화자 수가 주어지지 않았다면, 우선 $\hat{S}=max{s|s \in Z_{+} \wedge p_s >= \tau(threshold)}$를 만족하는 $\hat{S}$명의 attractor를 택하면 된다
  - Use Speaker Attractor: T x 256 -> T x S-1 (S: number of speaker attractor, last sepaker attractor는 silence speaker로 제외)
    - SA-EEND Block 에서 생성된 Embedding (Not Encoder output)에 Decoder에서 생성된 Speaker Attractor를 곱해서 Speaker 별 Frame-speaker activity 을 구해낸다.
    - 이 출력을 이용해서 SA-EEND와 동일한 PIT Loss를 이용하여 학습을 진행한다.
    - $\hat{Y} = \sigma(A^T E) \in R^{S\*T}$, $\sigma(\dot)$은 element-wise sigmoid function이다
    - 따라서 output size는 attractor의 개수에 따라 flexible하게 변경된다













