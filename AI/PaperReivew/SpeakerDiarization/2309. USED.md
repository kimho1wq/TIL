# USED: UNIVERSAL SPEAKER EXTRACTION AND DIARIZATION

### Introduction

multi-talker scenario에서 인간은 speech signal을 누가 말했는지(speaker extraction)의 정보를 바탕으로 언제 말했는지(diarization) 까지를 동시에 파악한다

speaker extraction은 highly overlapped speech 환경에서 최적화 되고, diarization은 mostly sparsely overlapped speech에서 연구된다

이 논문에서는 Universal Speaker Extraction and Diarization framework (USED)를 제안했고 highly overlapped과 sparsely overlapped된 speech를 효과적으로 다룰것을 기대한다
 
1. 현재 speaker extraction 모델에서 모든 speaker의 waveform을 동시에 추출하도록 하였다
2. Scenario-Aware Differentiated Loss (SAD)를 적용하여 다른 두개의 task에 적합하도록 objective 함수를 구현하였다
3. multi-task learning을 사용하기 때문에 diarization의 결과를 이용하여 background noise를 억제하고 target speech의 성능을 향상시켰다

speaker extraction에서 time domain으로 classify하는 것은 frequency domain에서 발생하는 위상 계산(phase estimation) 문제를 피할 수 있다

최근 speaker extraction system은 target speaker가 없을 경우 speech power를 최소화하고, target speaker가 있을 경우 signal-to-distortion(SDR) ratio 또는 scale-invariant(SI) SDR을 최대화하는 방향으로 진행되고 있다

하지만 이러한 방법은 독립적인 2개의 objectives function을 최적화 하는 방향으로 진행되므로 USED에서는 multi-task module을 활용하여 해결하고 있다

speech separation은 모든 speaker의 speech에 대하여 separate하는 것을 추구하고, speaker extraction은 그 시간에 오직 1명의 target speaker를 추출한다

또한 기존 speaker diarization system과 speech separation system의 공통 학습은 많이 연구되었지만, speaker extraction와 연구가 많이 없기 때문에 거기에 초점을 두었다



















