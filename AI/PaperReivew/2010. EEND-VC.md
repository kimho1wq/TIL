# INTEGRATING END-TO-END NEURAL AND CLUSTERING-BASED DIARIZATION: GETTING THE BEST OF BOTH WORLDS

## Introduction

clustering-based 접근은 다양한 challenging data에 state-of-the-art 접근법이지만,
overlap된 speech에는 적용하지 못하여 natural conversational data에 적용하기 힘들다

또한 비공식적인 일상 대화에서도 일반적으로 overlapped speech가 20% 정도 된다고 알려져 있다

반면 end-to-end neural diarization(EEND)는 frame-level spectral freature를 이용하여 frame-level speaker activity를 추출하기 때문에 overlapped speech를 다루는데 문제가 없다

하지만 EEND는 메모리에 한계가 있기 때문에 10분정도의 long recordings에 작동 시키기 불가능에 가깝고, unseen long sequential data를 일반화하기 어렵다는 문제가 있다

long recording이나 online method의 경우 audio를 segment화 하여 각각의 chunck를 독립적으로 EEND에 적용하는데 이때 inter-block label permutation problem(ambiguity fo the speaker label)이 발생한다

chunk단위로 inference를 수행 했을 경우 infer결과의 label의 permutation 매칭을 찾아야 한다는 문제가 발생하는데 이를 inter-block label permuation problem이라 한다


따라서 이 논문에서는 clustering-based diarization 시스템을 EEND에 결합하여 EEND-vector clustering(VC) 라는 hybrid diarization approach를 제안한다

proposed approach에서 가장 중요한 요소는 modified EEND network가 생성하는 global speaker embeddings with the diarization results 이다

SA-EEND을 동일하게 사용하며, 추가적으로 화자 인식과 speaker embedding을 생성하기 위한 loss를 추가하고,
constraint clustering을 통한 Inter-block label permutation perblem을 해결하였다


## Proposed framework
![image](https://github.com/kimho1wq/TIL/assets/15611500/d700d336-b713-453b-bb02-a670180a0c88)

- Main Proposal
  - multi-task learning with speaker identification
    - 입력 내 화자를 대표하는 speaker embedding을 생성하여, 화자 분류와 화자 인식을 동시에 학습한다
  - speaker embedding clustering
    - 각 inter-block으로 부터 대표 speaker embedding을 생성하고, 이 embedding에 clustering을 적용하여 inter-block label permutation problem을 해결한다
  - constraint clustering
    - 각 inter-block내 speaker가 다른 경우 같은 화자로 clustering되지 않도록 제약을 주는 방법
    - 즉, EEND의 결과로 다르다고 판명된 speaker에 대해서는 나중에 같은 speaker로 clustering되지 않도록 제약을 가한다

- SA-EEND block
  - 이전 SA-EEND 구조를 동일하게 사용했다.
  - Input: 23 log-mel, stacked sub-sampling
  - Number of header: H(4)
  - hidden dimension: D(256)
  - Number of Encoder block: if(Librispeech) P(4), if(CALLHOME) P(6) 
  - maximum number of speaker in each block: if(Librispeech) S(2), if(CALLHOME) S(3)
    - $X_i = (x_{t,i} | t = 1, \cdots , T)$, $i$는 chunk index, $t$는 chunk의 frame index, $T$는 chunk size 이다
    - $[h_{1,i}, \cdots, h_{T,i}] = Encoder(X_i) \in R^{D\*T}$
    - $\hat{y}_{t,i,s} = Sigmoid(Linear_s^D(h_{t,i})) \in (0,1)$, ($s=1,\cdots,S_{Local}$)
    - $Encoder(\dot)$은 multi-head self-attention NN, $Linear_s^D(\dot)$는 $R^D \to R^1$인 fully-connected layer

- Speaker embedding estimation
  - Linear: T x D -> T x C
    - SA-EEND의 output인 diarization task의 embedding을, speaker embedding의 embedding space로 변경한다
    - $z_{t,i,s} = Linear_s^S(h_{t,i}) \in R^C$
    - $\bar{z}_{i,s} = \displaystyle\sum_{t=1}^T{\hat{y_{t,i,s}} z_{t,i,s}} \in R^C$
    - $\hat{e}_{i,s} = \frac{\bar{z}_{i,s}}{||\bar{z}_{i,s}|| \in R^C}$
    - $Linear_s^S(\dot)$은 $R^D \to R^C$인 fully-connected layer이다

- Clustering Method
  - Constrained AHC(Agglomerative Hierarchical Clustering)
    - speaker embedding 간의 distance metrix(Cosine Similarity)를 이용하여 $D^{dist}$ score matrix를 생성한다
    - EEND와 같은 block 내의 score matrix 값인 $D_{i,i}$에 대해서는 같은 speaker로 되지 않도록 높은 값(ex, $inf$)으로 설정한다
  - Constrained SC(Spectral Clustering)
    - SC는 score matrix 값이 0인 경우 연결되지 않은 것으로 간주한다

- Loss: $L = (1-\lambda) L_{diarization} + \lambda L_{speaker}$
  - Diarization loss($L_{diarization}$)
    - 기존 SA-EEND loss와 동일
    - $L_{diarization} = \displaystyle\sum_{i=1}^B{L_{diarization, i}}$, $B$는 mini-batch size 이다
    - $L_{diarization, i} = \frac{1}{TS_{Local}} min_{\phi \in perm(S_{Local})} \displaystyle\sum_{t=1}^T{BCE(l_{t_i}^\phi, \hat{y_{t,i}})}$
    - $\hat{y}_{t,i} = [\hat{y}_{t,i,1}, \cdots, \hat{y}_{t,i,S_{Local}}] \in R^{S_{Local}}$
    - $l^\phi_{t,i}$는 permutation speaker label 이다
  - Speaker Embedding loss($L_{speaker}$)
    - 화자 인식 정보를 이용하기 위한 multi-task loss term
    - $L_{speaker, i} = \frac{1}{S_{Local}}\displaystyle\sum_{s=1}^{S_{Local}}{l_{speaker}(\sigma^\ast_{i,s}, \hat{e}_{i,s})}$
    - $l_{speaker}(\sigma^\ast_{i,s}, \hat{e}_{i,s}) = ln(\frac{exp(-d(\alpha||E_{\sigma^\ast_{i,s}} - \hat{e}_{i,s}||^2 + \beta))}{\displaystyle\sum_{m=1}^M{exp(-d(\alpha||E_m - \hat{e}_{i,s}||^2 + \beta))}}) $
    - $\sigma_{i,s}$: i번째 chunk의 s번째 slot의 global speaker index
    - $\ast$: diarization loss에서 찾은 최적의 permutation
    - $\hat{e}_{i,s}$: i번째 chuck의, s번째 slot의 speaker embedding $\in (1\*C)$
    - $m$: global speaker index 값 ($1,\cdots, M$), $M$: training set 전체 화자 수
    - $\alpha, \beta$: distance matrix의 learnable한 scaling 값과 bias factor 값

- $S_{Local}$ 
  - $S_{Local}$은 hyper-parameter로 maximum number of active speaker in a chunk를 의미한다
  - 이 논문에서는 $S_{Local}=2$로 설정하였고, network는 각 chunk에서 2명의 speaker를 기준으로 diarization result를 만들어 낸다
  - $S_{Local} <= S_{total}$ 을 만족해야 하고, $S_{total}$은 recording의 총 speaker의 수 이다  
  - $S_{Local}$은 하나의 chunk에 존재하는 speaker의 수보다 많거나 같아야 한다
    - 만약 하나의 block 내의 $S_{Local}$보다 작은 화자 수가 존재하는 경우에 Silence Speaker를 판단해야 한다
    - 이 논문에서는 heuristic한 방법으로 전체 시간 중 $\tau(5) %$이상의 speaker activity region이 존재하지 않는 경우($\frac{1}{T}\displaystyle\sum_{t=1}^T{\hat{y}_{t,i,s}} < \tau$) silence speaker로 간주하였다
    - 또한 $Y_i$의 diarization label을 가상의 $(S_{total}+1)$번 째의 label을 항상 silent speaker의 label로 지정한다

- inference chunk 길이
  - chunk의 길이가 짧은 경우
    - EEND의 속도 향상
    - chunk 내 화자 수가 적을 확률이 높음
    - clustering의 부담이 늘어남
    - 좋은 speaker embedding을 만들어 내기 어려움
  - chunk의 길이가 긴 경우
    - EEND의 속도 저하
    - chunk 내 화자 수가 많을 확률이 올라감
    - clustering의 부담이 줄어듬
    - 보다 좋은 speaker embedding을 만들기 유리해짐
  - 30초 일때 가장 좋은 성능을 보여줌








