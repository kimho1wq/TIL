# 준지도 학습과 전이 학습

### 표현 학습
- 표현 학습(representation learning)은 특징 추출과 분류를 기계 학습에서 동시에 최적화하는 접근방식을 의미한다
  - 표현 학습은 데이터 생성 확률분포에서 수집한 훈련집합으로 작동하며, 패턴의 변화는 여러 가지 변화 인자(factor of variation)에 따라 이루어진다
  - 패턴의 변화 인자는 원래 특징 공간의 차원 수보다 훨씬 적은 수로 발생하며, 이러한 변화 인자를 따로따로 풀기 위해서는 사전 지식(prior)을 사용해야 한다
  - 표현 학습은 명시적으로 정의되어 있어 목적함수가 존재하는 문제가 아니라 기계 학습 전반에 걸쳐 암시적으로 도움을 주는 과정이다

### 내부 표현
- 학습 결과로 얻은 은닉층의 내용 등의 내부 표현을 가시화(visualization)하여 신경망을 이해하고 통찰력을 얻을 수 있다
- 내부 표현 가시화 방법
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/9aa6a58d-1a37-46a9-a69a-d3cf22fdd769)
  - 컨볼루션 필터의 가시화
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/a5a000b2-562d-48cc-a342-a10622b38d9e)
  - 특징 맵의 가시화
    - 필터를 적용하여 얻은 특징 맵을 가시화하는 방법으로, 신경망 노드의 활성값을 가시화하는 방법이다 
  - 하나의 노드를 영상 공간으로 역투영
    - 입력 공간에서의 영역을 가시화하는 역투영(back-projection) 기법으로, 하나의 노드 또는 같은 층에 있는 여러 뉴런의 집합을 활성화하는 부분을 가시화한다
    - 최적화를 이용한 역투영
      - 관찰하고자 하는 뉴런을 $i$로, $a_i(x)$를 영상 $x$가 입력되었을 때 뉴런 $i$의 활성값이라 하면 $a_i(x)$를 최대화하는 $x$를 찾으면 된다 $(\hat{x} = argmax_x{a_i(x)})$
      - 초기에는 사전 지식(prior)를 활용하지 않아 규제 항이 없었지만, 자연영상에 적합한 프라이어(prior)를 고려하여 점차 개선된 목적함수를 찾아 경사 상승법으로 문제를 해결하였다
        - $\hat{x} = argmax_x(a_i(x) - R_\Theta(x))$, $x_{t+1} = r_\Theta(x_t + \eta\frac{\partial (a_i(x) - R_\Theta(x))}{\partial x})$
  - 특징 맵 전체를 역투영
    - 한 뉴런이 아니라 한 특징 맵이 보고자 하는 영상을 가장 활성화하는 영상을 찾는다
    - 특징 맵 천제를 파악하기 위해서 CNN이 사용하는 연산을 역으로 적용하여 시각화하는 디컨볼루션(deconvolution) 기법도 가능하다
      - CNN에 입력 양상 $I$를 이용하여 전방 계산(feedforward)를 계산하고, 역투영하고자 하는 층에서 출발하여 역방향으로 연산하면서 입력 공간까지 진행한다
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/43e51f13-0b34-4693-a577-680889ecbf7d)
  
### 준지도 학습
- 준지도 학습(semi-supervised learning)은 레이블이 있는 데이터와 레이블이 없는 데이터를 동시에 이용하며, 보통 레이블이 없는 샘플이 훨씬 많다고 가정한다
- 학습 알고리즘
  - 현대적 생성 모델
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/e653db27-b1a0-4618-888d-d92aac70c536)
    - 원래 부류의 수가 c라면 가짜 샘플을 위해 c+1의 레이블을 추가로 사용한다
    - 목적함수는 3개의 항을 가지며, 가짜 샘플을 c+1 부류에 배정하고 $X_u$ 샘플을 c+1 부류에 속하지 않게 하며 $X_l, T_l$의 샘플은 자신의 부류에 속하도록 강제한다
  - 자가 학습(self-training)
    - 먼저 $X_l$과 $Y_l$로 지도 학습을 수행한 후 $X_u$의 샘플을 분류한다
    - 이렇게 분류된 샘플 중 신뢰도가 높은 샘플을 부분집합 $X_{u_subset}$을 구성하고, 새로 얻은 부류 정보 $Y_{u_subset}$과 함께 $X_l, Y_l$로 옮긴다
    - 늘어난 $X_l$과 $Y_l$로 분류기를 다시 학습시키고 이러한 과정을 반복한다
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/f1807d70-ba4b-41b2-bc06-7e9d893246bd)
    - 다만, 데이터 분포에 잘 들어맞는 분류기 모델을 선택하는 일이 매우 중요한 방법이다
  - 협동 학습(co-training)
    - 학습기 2개가 서로 가르쳐 주는 과정을 반복하면서 같이 발전하는 전략을 사용하는 방법이다
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/b1627948-e022-4f07-a537-6a7d940c82f5)
  - 그래프 방법
    - $X_l$과 $X_u$를 합친 다음, 그 속에 있는 샘플 각각을 노드로 삼고 이웃한 노드 사이에 에지를 놓는다
    - 두 샘플의 유사도에 따라 에지에 가중치가 부여되며, 최소 분할(mincut)이라는 기법을 적용한다
    - 최소 분할(mincut)은 같은 레이블을 가진 샘플은 같은 부분집합에 속하면서, 분할선을 구서아는 에지의 가중치 합이 최소가 되로록 노드를 두 부분집합으로 분할한다
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/3e026ebe-d090-4c74-9f6d-0f6266b2c232)
      - 분할선을 구성하는 에지 가중치의 합이 $1+2+2=5$로 최소이며, 빨간 노드는 $X_l$, 하얀 노드는 $X_u$에 속한다
    - 최소 분할선은 유사도가 가장 작은 에지들로 구성되므로, 데이터 분포가 가장 희소한 곳을 분할 경계로 삼았다고 볼 수 있다
    - 최소 분할 알고리즘
      - $J(\Theta) = \displaystyle\sum_{i=1}^n{\infty(y_i - \theta(x_i))^2} + \lambda\displaystyle\sum_{j=n+1}^{n+m}\displaystyle\sum_{k=n+1}^{n+m}{w_{jk}(\theta(x_j) - \theta(x_k))^2}$
      - $J(\Theta)$를 최소화 하는 해를 찾으며, $\theta(x_i)$는 $i$번째 노드에 최종으로 부여되는 레이블값을 의미한다
      - 첫 번째 항은 $X_l$에 있는 샘플의 레이블을 그래도 유지하게 강제화 하는 역할을 하며, 두 번째 항은 $j$와 $k$노드를 잇는 에지의 가중치로 규제 역할을 수행한다

### 전이 학습
- 전이 학습(transfer learning)은 다른 과업(task)이나 도메인(domain)의 정보를 데이터가 적은 새로운 도메인에 적용하여 높은 성능을 얻고자 하는 학습 방법이다
  - 과업(task)가 달라지는 경우는 영상 인식의 정보를 음성 인식에서 사용하는 것 처럼 응용분야가 다른 경우이다
  - 도메인(domain)이 달라지는 경우는 한영 번역기를 한일 번역기로 전이하는 것과 같이 특징 공간이 다른 경우나, 한국에서 쓴 필기숫자 데이터베이스를 인도에서 사용하는 것과 같이 특징 공간은 같은데 데이터의 확률분포가 다른 경우로 구분한다 
- 과업(task) 전이
  - 학습 적용 방법으로 동결(freezing) 방식, 미세 조정(fine tuning) 방식 등을 사용할 수 있다
- 도메인 전이
  - 도메인 적응(domain adaptation): 특징 공간은 같은데 확률분포가 다른 경우를 의미하며, 높은 성능을 유지하면서 도메인 이동(domain shift)를 달성하는 기법이다
  - 원천 도메인(source domain, $X_s$)이 목표 도메인(target domain, $X_t$)보다 보통 훨씬 많은 데이터를 가지고 있으며, $n >> m$이다
  - 도메인 적응 알고리즘
    - 지도 학습에 적용
      - 우선 특징 벡터의 크기를 3배로 확장한다 $\Phi^s(x_s) = (x_s^T, x_s^T, 0)^T, \Phi^t(x_t) = (x_t^T, 0, x_t^T)^T$, 이 식에서 $0$은 $d$차원의 0벡터 이다
      - 확장한 $m+n$개의 샘플을 가지고 학습기를 학습한 다음 목표 도메인에서 활용하면 된다 (원천 도메인과 목표 도메인이 공유하는 $3d$ 차원의 공간으로 모든 샘플을 변환하는 것)
    - 비지도 학습에 적용
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/77b6f463-3e74-47b1-8deb-8a8e894c61b9)
      - 원천 도메인의 샘플($X_s$)을 목표 도메인의 분포($X_t$)에 맞도록 변환하기 위해서 두 도메인의 공분산 행렬을 같게 만들어준다
      - 원천 데이터에 화이트닝(whitening) 변환을 적용한 후, 컬러링(coloring) 변환을 적용하면 
        - 화이트닝(whitening): 데이터의 평균을 0, 그리고 공분산을 단위행렬로 갖는 정규분포 형태로 변환하는 기법으로 Decorrelation + Standardization으로 볼 수 있다
        - 컬러링(coloring): 화이트닝과 반대 기법
      - 원천 도메인의 공분산: $\Sigma^\prime_s = \Sigma_s + \lambda I$, 목표 도메인의 공분산: $\Sigma^\prime_t = \Sigma_t + \lambda I$
      - 화이트닝: $X^\prime_s = X_s(\Sigma^\prime_s)^{-\frac{1}{2}}$, 컬러링: $X^\ast_s = X_s^\prime(\Sigma^\prime_t)^{\frac{1}{2}}$











  























