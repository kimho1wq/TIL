# 딥러닝 최적화

### 교차 엔트로피와 로그우도
- 딥러닝에서 평균제곱 오차(MSE)를 목적함수로 사용하면 시그모이드(sigmoid)의 도함수($\sigma^\prime$)로 인해 더딘 학습현상이 발생할 수 있다
  - $\frac{\partial e}{\partial w} = -(y-o) x \sigma^\prime (wx+b)$
  - $\frac{\partial e}{\partial b} = -(y-o) \sigma^\prime (wx+b)$
- 교체 엔트로피(cross entropy)를 기반으로 한 목적함수
  - $H(P,Q) = -\displaystyle\sum_{y \in {0,1}}{P(y)\log_{2}{Q(y)}}$ )
  - 여기서 $y$가 확률변수 역할을 하며, y는 정답 레이블을 가지므로 $y \in {0,1}$이다
  - $P$를 정답 레이블, $Q$를 신경망의 출력으로 가정한다면 다음과 같은 수식으로 통일할 수 있다
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/aa16fc6c-4788-4970-b7af-fb9b48114c50)
    - P(1) = y, Q(1) = o, $P(0) = 1-y, Q(0) = 1-o$
    - $o = \sigma(z)$, $z = wx+b$
    - $E = -(ylog_2 o + (1-y)log_2(1-o))$
      - ```
        y=1, o=0.98일 경우,
        e = -(1*log0.98 + 0*log0.02) = 0.0291
        y=1, o=0.001일 경우,
        e = -(1*log0.0001 + 0*log0.9999) = 13.2877
        ```
    - $\frac{\partial e}{\partial w} = -(\frac{y}{o}-\frac{1-y}{1-o}) \frac{\partial o}{\partial w}$
      - $= -(\frac{y}{o}-\frac{1-y}{1-o}) \frac{\partial z}{\partial w} \frac{\partial o}{\partial z} $
      - $= -(\frac{y}{o}-\frac{1-y}{1-o}) x\sigma^\prime(z)$
      - $= -(\frac{y}{o}-\frac{1-y}{1-o}) x \sigma(z)(1-\sigma(z)) $
      - $= -(\frac{y}{o}-\frac{1-y}{1-o}) xo(1-o) $
      - $= x(o-y) $
    - $\frac{\partial e}{\partial b} = (o-y)$
  - c개의 출력 노드를 가진 신경망에서의 cross entropy
    - $E = -\displaystyle\sum_{i=1,c}{(y_ilog_2 o_i + (1-y_i)log_2(1-o_i))}$
- 로그우도(log likelihood)
  - 모든 노드값을 고려하지 않으며, 샘플의 레이블에 해당하는 노드의 출력값 $o_y$ 하나만 본다
  - $E = -log_2 o_y$
    - ```
      y=2, output2=0.0508 일때, 오류값(e) = log0.0508 = 4.2990
      y=3, output3=0.8360 일때, 오류값(e) = log0.8360 = 0.2584
      ```
- softmax 활성함수
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/14e6150d-321c-4033-b811-3d4be1b622a9)
  - 출력 노드에서 주로 사용하며 softmax의 출력값을 모두 더하면 1이되고, 최대값을 더욱 활성화하고 작은 값을 더 억제하는 효과를 낼 수 있다 (max 함수에 가깝지만 더 부드럽다)
  - 학습 샘플이 알려 주는 부류에 해당하는 출력 노드값에 집중하기 때문에, 로그우도(log likelihood)와 결합하여 자주 사용된다


### 성능 향상을 위한 기법
- 표준화(standardization)
  - 특징값이 모두 양수일 경우 여러 가중치가 다같이 증가하거나 감소하면 최저점을 찾아가는 경로가 모호해져서 수렴 속도가 저하된다
  - 특징값의 규모가 다를 경우 ($x_1$이 $x_2$보다 값의 규모가 100배 정도 작다면) 규모가 작은 특징은($x_1$) 더 느리게 학습된다
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/c3539570-a861-4d8d-a09a-f80ea5ad4155)
  - 따라서 특징값의 평균이 0이 되도록 변환하고, 모든 특징의 표준편차를 1.0으로 통일하면 학습 속도를 균일하게 맞출 수 있다
    - $x_i^{new} = \frac{x_i^{old} - \mu_i}{\sigma_i}$, $x_i^{new}$는 z-score 또는 표준점수라고 한다
    - 더 중요한 특징이 존재한다면 그 특징의 표준편차를 크도록($>1.0$) 변환시킬 수 있다
  - 정규화(normalization)는 Min-max normalization으로 값의 범위를 0~1사이로 옮겨주는 것 이라고 한다
- 가중치 초기화
  - 대칭적 가중치(symmetry weight)가 발생한 경우
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/9db1a3eb-4217-48a6-ae58-f6b24f559af6)
    - $l-1$층의 두 노드 $z_1^{l-1}$값과 $z_2^{l-1}$ 값이 같아지고, 오류 역전파에서 $u^l_{11}, u^l_{12}$과 $u^l_{21}, u^l_{22}$이 같은 값으로 갱신되버리는 문제가 발생한다
    - 결국, $l-1$층의 두 노드는 같은 일을 하는 셈이 되어서 중복성 문제가 발생
  - 초기 가중치를 초기할 때, 가중치가 0에 너무 가깝다면 gradient가 작아져 학습이 매우 느려지고, 너무 크면 과잉적합(overfitting)이 발생할 수 있다
  - [Glorot2010]이 제시한 가중치 난수 초기화 방법
    - $r = \frac{\sqrt{6}}{\sqrt{n_{in} + n_{out}}}$을 결정한 후, $[-r, r]$의 범위의 난수를 생성하는 방식
    - $n_{in}, n_{out}$은 각각 노드로 들어오는 edge의 개수와 나가는 edge 개수를 의미한다
  - AlexNet은 평균이 0이고 표준편차가 0.01인 가우시언 분포(gaussian distribution)에서 생성된 난수로 가중치를 초기화하였다
  - 또한, 노드의 출력값 분포를 일정하도록(출력값의 분산이 1이 되도록) 강제화하는 방법도 있다 ([Mishjin2016])
- 모멘텀(momentum)
  - gradient에 스무딩(smoothing)을 가하면서 수렴 속도를 개선하는 방법이다
  - 이동량이 너무 커 적잘한 곳을 지나치는 오버슈팅(overshooting) 현상이 존재할 때 더욱 빠르게 최적해를 찾을 수 있다
  - 물리에서 모멘텀은 질량 x 속도 이지만, 신경망에서의 질량은 1이라 가정하여 속도를 나타내는 벡터 $v$를 사용한다
  - 처음 시작할 때는 v=0으로 놓고 시작하며, 미니배치를 사용한다면 $\frac{\partial J}{\partial \theta}$를 미니배치의 평균으로 대치한다
    - $v = \alpha v - p\frac{\partial J}{\partial \theta}$
    - $\theta = \theta + v$
    - $\alpha$는 $[0,1]$범위에서 이전 gradient에 가중치를 부여하며, $p$는 learing rate
  - 네스테로프 모멘텀(Nesterov-momentum) 기법
    - 모멘텀 기법을 개선하여 현재 $v$값을 이용하여 다음 이동할 $\tilde{\theta}$를 미리 예견(lookahead)한 후, 그곳의 gradient를 사용하는 방식
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/72afd531-156c-435e-bb00-322a3b08ba15)
    - $\tilde{\theta} = \theta + \alpha v$
    - $v = \alpha v - p\frac{\partial J}{\partial \theta}|_{\tilde{\theta}}$
    - $\theta = \theta + v$
- 적응적 학습률(adaptive learning rate)
  - k개의 매개변수( $p\frac{\partial J}{\partial \theta} = (p\frac{\partial J}{\partial \theta_1}, \cdots, p\frac{\partial J}{\partial \theta_k})^T$ )가 각각 자신의 상황에 따른 학습률(p)을 조절해 사용하도록 하는 기법
  - learning rate인 $p$가 너무 높으면 오버슈팅(overshooting)의 진자 운동이 생기고 너무 낮으면 오랜 시간이 걸린다
  - 적응적인 학습률 조절 작업을 담금질하다(annealing) 라고도 한다 
  - AdaGrad(adaptive gradient)
    - 매개변수별로 그레디언트 누적 벡터값 $r$과 갱신값 $\Delta \theta$를 계산한다
    - 이전 gradient의 누적값($r_i$)가 크면 $|\Delta \theta_i|$는 작아져서 조금만 이동하게 되며, 작으면 많이 이동하게 된다
    - $\frac{p}{\epsilon + \sqrt{r}}$이 상황에 따라 보폭을 정해 주는 정응적 학습률이 된다
    - $\epsilon$은 분모가 0이 되는 것을 방지하는 역할, $\odot$은 요소별 곱, $g = \frac{\partial J}{\partial \theta}$
    - $r=0$로 초기화한다
      - $r = r + g \odot g$
        - $(r_1, \cdots, r_k)^T = (r_1 + g_1^2, \cdots, r_k + g_k^2)^T$
      - $\Delta \theta = -\frac{p}{\epsilon + \sqrt{r}} \odot g$
        - $(\Delta \theta_1, \cdots, \Delta \theta_k)^T = (-\frac{p g_1}{\epsilon + \sqrt{r_1}}, \cdots, -\frac{p g_k}{\epsilon + \sqrt{r_k}})^T$
      - $\theta = \theta + \Delta \theta$
        - $(\theta_1, \cdots, \theta_k)^T = (\theta_1 + \Delta \theta_1, \cdots, \theta + \Delta \theta_k)^T$
    - 다만, 오래된 gradient와 최근 gradient가 알고리즘이 끝날 때까지 같은 비중의 역할을 하기 때문에, r이 점점 커져 수렴하지 못한 상황에서 p가 0에 가까워질 수도 있다
  - RMSProp
    - 오래된 gradient의 영향력을 지수적으로 줄이기 위해 가중 이동 평균(weighted moving average)기법을 적용한다
    - $\alpha$는 $0.9, 0.99, 0.999$와 같은 값을 사용한다
    - $r=0$로 초기화한다
      - $r = \alpha r + (1-\alpha) g \odot g$
      - $\Delta \theta = -\frac{p}{\epsilon + \sqrt{r}} \odot g$
      - $\theta = \theta + \Delta \theta$
  - Adam(adaptive moment)
    - RMSProp에 모멘텀 기법을 추가로 적용한 알고리즘이다
    - $r=0, v=0, t=1$로 초기화한다
      - $v = \alpha_1 v - (1-\alpha_1) g$
      - $v = \frac{1}{1-(\alpha_1)^t}v$
      - $r = \alpha_2 r + (1-\alpha_2) g \odot g$
      - $r = \frac{1}{1-(\alpha_2)^r}v$
      - $\Delta \theta = -\frac{p}{\epsilon + \sqrt{r}} \odot v$
      - $\theta = \theta + \Delta \theta$
      - $t++$
- 배치 정규화(batch normalization)
  - 배치 정규화는 공변량 시프트(covariate shift) 문제를 해결하기 위해, 모든 층에서 독립적으로 표준 정규화(standardization)를 적용하는 기법이다
  - 공변량 시프트
    - 입력되는 샘플의 분포($\tilde{X}^{(l-1)}$)가 학습 과정에서 계속 바뀌는 현상
    - 공변량 시프트는 층이 깊어질수록 심해지는데, 이는 깊은 구조의 신경망이 잘 학습되지 않는 이유 중 하나이다
  - 배치 정규화를 적용하면 매개변수의 초깃값에 덜 민감하고, 학습률을 크게 설정하여 수렴 속도를 향상시킬 수 있으며, 규제 효과도 제공한다
  - $z = w^T\tilde{x} + b$, $y = \tau(z)$에서 activation function을 적용하기 전의 중간 결과 z에 적용하는 것이 성능 실험결과 더 좋았다
  - 또한 훈련집합 전체에 적용하는 것보다 미니배치(mini batch) 단위로 적용하다는 것이 성능이 좋다는 실험결과가 존재한다
  - 배치 정규화 적용
    - 미니배치는 $\tilde{X_b} = \{z_1, \cdots, z_m\}$로, 미니배치의 크기는 $m$이다
      - $\mu_B = \frac{1}{m}\displaystyle\sum_{i=1}^m{z_i}$
      - $\sigma_B^2 = \frac{1}{m}\displaystyle\sum_{i=1}^m{(z_i-\mu_B)^2}$
      - $\tilde{z_i} = \frac{z_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$, $(i=1,2,\cdots,m)$
      - $z_i^\prime = \gamma \tilde{z_i} + \beta$, $(i=1,2,\cdots,m)$
    - 정규화 변환값 $\tilde{z_i}$에 선형 변환을 수행하여 얻은 $z^\prime_i$를 활성함수(activation function)에 입력한다
      - $\gamma$와 $\beta$는 노드마다 고유한 매개변수로서 학습으로 알아내는 변수이다
      - $\gamma$와 $\beta$는 정규화 연산을 보정하여 원래 값에 가깝게 재조정 하는 역할을 수행한다 ($\gamma = \sqrt{\sigma^2 + \epsilon}, \beta = \mu$가 되면 $z^\prime = z$가 된다)
      - 실제로는 $\gamma$와 $\beta$를 학습으로 알아내므로 배치 정규화 효과가 사라지지 않으며, 훈련집합에 적합한 값으로 설정된다
      - $\beta$가 바이어스(bias) 역할을 수행하므로 바이어스 항 $b$를 제거하여 $z = w^T\tilde{x}$로 사용해도 된다
    - 예측 단계에서 계산하기 위한 $\mu, \sigma^2, \gamma, \beta$ 변수들을 노드에 저장한다
    - 컨볼루션 신경망에서는 노드 단위가 아니라 특징 맵(feature map) 단위로 적용한다
      - 특징 맵의 크기가 $p*q$라면, $\mu$와 $\sigma^2$는 $pqm$개의 값을 가지고 계산된다
      - 특징 맵 하나 당 $\gamma$와 $\beta$가 하나씩 존재한다


### 규제 기법
- 규제(regularization) 기법은 주로 과잉적합(overfitting)을 방지하기 위해 사용된다
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/ae18aa1a-c435-4c59-a94c-5d8c1ca5b604)
  - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda R(\Theta)$
  - 규제항($R$)은 가중치의 크기에 제약을 가하는 역할을 수행한다
  - 가중치는 노드 사이의 상호작용을 표현하기 때문에 규제가 필요하지만, 바이어스(bias)는 하나의 노드에만 관련되기 때문에 규제를 하면 오히려 과소적합이 될 수 있다
- 가중치 감쇠(weight dacay) 기법
  - L2 놈 사용
    - L2 놈의 제곱을 규제 항$(R)$로 사용한다
    - $||\Theta||_2 = (\displaystyle\sum_i^d{\Theta_i^2})^{\frac{1}{2}}$
    - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda ||\Theta||_2^2$
    - gradient를 이용하여 매개변수를 갱신하는 식
      - $\Theta = \Theta - p \nabla J_{regularized}(\Theta;X,Y)$
        - $= \Theta -p(\nabla J + 2 \lambda \Theta)$
        - $= (1-2p\lambda)\Theta - p\nabla J$
    - L2 놈의 계수인 $\lambda$를 0으로 설정하면 규제를 적용하지 않은 원래 식이 된다
    - 보통 $2p\lambda$ 1보다 작은 수를 사용하고, 해를 원점 가까이 당기는 것과 동일한 효과를 준다
  - L1 놈 사용
    - $||\Theta||_1 = \displaystyle\sum_i^d{|\Theta_i|}$
    - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda ||\Theta||_1$, $(\nabla \lambda||\Theta||_1 = \lambda sign(\Theta))$
    - $sign(\Theta)$는 $\Theta_i$의 부호로 구성되는 벡터로, 벡터의 요소는 양수이면 1, 음수이면 -1을 가진다
    - gradient를 이용하여 매개변수를 갱신하는 식
      - $\Theta = \Theta - p \nabla J_{regularized}(\Theta;X,Y)$
        - $= \Theta -p(\nabla J + \lambda sign(\Theta))$
        - $= \Theta - p\nabla J - p\lambda sign(\Theta)$
    - L1 놈을 사용하면 0이 되는 매개변수가 많아지는 희소성(sparsity) 현상이 생길 수 있다
    - L1 놈도 해를 원점 방향으로 당기는 효과가 있다
- 조기 멈춤(early stopping)
  - 일반화 능력이 최고인 지점에서 학습을 종료시키는 방법
  - 가장 단순한 방법은 t이후에 연속으로 p번 동안 성능 향상이 없으면 멈출 수 있다
  - p를 참을성 인자 라고도 한다
- 데이터 확대(data augmentation)
  - 과잉적합을 방지하는 가장 확실한 방법은 충분히 큰 훈련집합을 사용하는 것이다
  - 이동, 회전, 크기변환 등의 선형 변환 또는 어파인 변환(affine transformation)으로 데이터의 양을 늘릴 수 있다
  - 잡음을 섞는 방법이나, PCA 변환을 적용한 후 고유벡터과 고윳값으로 색상을 변경하는 방법 등도 가능하다
- 드롭아웃(dropout)
  - 입력층과 은닉층의 노드 중 일정 비율을 임의로 선택하여 제거하는 작업이다
  - 선택된 노드는 자신에게 들어오는 엣지와 자신에서 나가는 엣지까지 모드 제거하는 작업이다
  - 드롭아웃을 여러 개의 예측기를 결합하는 앙상블(ensemble) 기법으로 볼 수도 있으며, 가중치를 공유하여 하나의 신경망을 사용하는 앙상블 기법이라고도 한다
  - dropout을 적용한 신경망의 예측단계에서는 학습때와 동일하게 p 비율의 노드를 줄인 다음 inference를 실시한다
  - 노드 제거 여부를 표시하는 boolean 배열을 이용하여 feedforward와 backpropagation을 실시한다
- 앙상블(ensemble) 기법
  - 여러 모델의 예측한 결과를 결합하여 일반화의 오류를 줄이는 방법
  - 앙상블의 기법은 배깅(bagging or bootstrap aggregating), 부스팅(boosting) 등이 있다


### 2차 미분을 이용한 최적화
- 실제 데이터는 잡음이 많은 불량 조건(ill-conditioned) 목적함수를 최적화 해야 하며, 1차 미분정보인 gradient는 완벽한 원형일때의 최저점의 방향을 계산해준다
- 뉴턴 방법
  - $w$가 $m$차원 벡터, $\delta$와 $\nabla J$는 $m$차원 벡터, $H$는 $m*m$행렬이다
  - $w + \delta$인 점이 최소점이라 가정하면 테일러 급수의 식으로 전개할 수 있다
    - 변수가 1개
      - $J(w+\delta) \approx J(w) + \frac{J^\prime(w)}{1!}\delta + \frac{J^{\prime\prime(w)}}{2!}\delta^2$
      - $\frac{\partial J(w + \delta)}{\partial \delta} \approx J^\prime(w) + \delta J^{\prime\prime}(w)$
      - 식을 = 0 으로 놓고 정리하면, $\delta = -\frac{J^\prime(w)}{J^{\prime\prime}(w)} = -(J^{\prime\prime}(w))^{-1}J^\prime(w)$
    - 변수가 2개 이상
      - $J(w+\delta) \approx J(w) + \frac{\nabla J^T \delta}{1!} + \frac{\delta^T H \delta}{2!}$
      - $\delta = -H^{-1}\nabla J$
  - $\delta$는 최저점의 방향을 가르키는 벡터이다
  - 헤시안$H$의 $m*m$ 행렬 값을 구해야하기 때문에 저차원 함수에만 적용할 수 있다는 한계가 있고, 헤시안이 양의 정부호 행렬일 때만 작용한다
  - 또한 헤시안의 역행렬을 구하기 위해선 $O(m^3)$의 시간이 소요된다
- 켤레 그레디언트(conjugate gradient) 방법
  - 헤시안 행렬을 사용하지 않고 그레디언트 정보로부터 2차 미분 정보를 근사하는 방법
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/9ba7a13b-641a-4987-acdf-88f7d7df3ddb)
  - 경사 하강법의 직선 탐색(line search)할 때 진적에 사용한 g_{t-1}의 정보를 고려하여 계산한다
    - $p^T_t H p_{t-1}$
  - 2차 함수를 가정하고 유도된 식으로 헤시안($H$) 행렬을 사용 안할 수 있다
    - $p_t = -g_t + \beta_t p_{t-1}$
    - Polak-Ribiere: $beta_t = \frac{(g_t - g_{t-1})^T g_t}{g_T_{t-1}g_{t-1}}$
    - Fletcher-Reeves: $beta_t = \frac{g^T_t g_t}{g^T_{t-1}g_{t-1}}$
    - $g_{t-1}$과 $g_t$는 직전의 그레디언트와 현재 그레디언트이다
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/ecd28b0f-bb22-4b58-8e04-3e11dd153285)
    - $q$번에 한 번씩 $\beta$를 리셋하여 원래 그레디언트를 사용하도록 조정하면 2차 함수가 아니여도 적용할 수 있다
    - $\Theta_t$와 $\Theta_t + \epsilon p_t$를 잇는 직선의 여러 점을 조사하여 최소점을 찾는 별도의 계산이 필요하다
- 유사 뉴턴(quasi newton) 방법
  - 헤시안의 역행렬을 근사하는 행렬 M을 사용하는 방법이다
  - 유사 뉴턴 방법 중 가장 널리 쓰이는 알고리즘은 BFGS(Broyden-Fletcher-Goldfarb-Shanno) 알고리즘 [LeCun2012]이다
  - 다만 BFGS의 근사 행렬 M을 저장하려면 과다한 메모리가 필요하기 때문에, L-BFGS(limited memory BFGS)를 사용한다







