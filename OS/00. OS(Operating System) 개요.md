## OS(Operating System) 이란
- 운영체제(OS, Operating System)는 사용자가 컴퓨터를 쉽게 다루게 해주는 인터페이스로 한정된 메모리나 시스템의 자원을 효율적으로 분배해준다
- 운영체제 역할
  1. CPU 스케줄링과 프로세스 관리: CPU 소유권을 어떤 프로세스에 할당할지, 프로세스의 생성과 삭제, 자원 할당 및 반환을 관리한다
  2. 메모리 관리: 한정된 메모리를 어떤 프로세스에 얼만큼 할당해야 하는지 관리한다
  3. 디스크 파일 관리: 디스크 파일을 어떤 방법으로 보관할지 관리한다
  4. I/O 디바이스 관리: 마우스, 키보드와 같은 I/O 디바이스간에 데이터를 주고 받는 것을 관리한다
- 운영체제 구조
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/f8442bba-fd65-4a43-a1f3-c5ba0e597c00)
    - GUI(Graphical user Interface): 사용자가 편리하게 사용하도록 입출력등의 기능을 그래픽으로 구현
    - 커널: 시스템콜 인터페이스를 제공하며 보안, 메모리, 프로세스, 파일 시스템과 I/O관리 등 운영체제의 중추적인 역할을 한다
    - 드라이버: 하드웨어를 제어하기 위한 소프트웨어
  - 시스템콜
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/9acf384c-4ec4-456e-9b17-6764879ad0a4)
    - 운영체제가 커널에 접근하기 위한 추상화된 인터페이스로, 유저 프로그램이 운영체제의 서비스를 받기 위해 시스템콜을 통해 커널에 접근한다
    - 유저 프로그램의 I/O 디바이스 등과 같은 컴퓨터 자원에 대한 직접 접근을 차단하고 보호할 수 있다
- 컴퓨터의 요소
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/d268734a-2e08-4d55-9ca1-2c0a955ecfea)
  - CPU(Central Processing Unit)
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/fd063350-f968-4cf1-b592-beba4a79a3f4)
    - 산술논리연산장치, 제어장치, 레지스터로 구성되어 있는 컴퓨터 장치로, 메모리에 존재하는 명령어를 해석해서 실행한다
      - 제어장치(CU, Control Unit)는 I/O장치의 통신을 제어하고 명령어들을 읽고 해석하며 데이터 처리를 위한 순서를 결정한다
      - 레지스터(Register)는 CPU 안에 있는 임시기억장치로 메모리보다 훨씬 빠르다
      - 산술논리연산장치(ALU, Arithmetic Logic Unit)는 산술 연산(덧셈,뺄셈 등)과 논리 연산(배타적 논리합,논리곱 등)을 계산하는 디지털 회로이다
    - 관리자 역할을 하는 운영체제의 커널이 프로그램을 메모리에 올려 프로세스를 생성하면 이를 CPU가 처리한다
    - 인터럽트(interrupt)
      - 어떤 신호가 들어왔을 때 CPU를 잠깐 정지시키는 것을 의미하며, 인터럽트가 발생되면 이를 처리하기 위한 인터럽트 핸들러 함수가 실행된다
      - I/O 디바이스 등에서 발생하는 하드웨어 인터럽트와 프로세스 오류 등으로 시스템콜을 호출할 때 발생하는 소프트웨어 인터럽트로 나뉜다
  - DMA 컨트롤러
    - I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치를 의미한다
    - 과도한 인터럽트에 대한 CPU 부하를 막아 주며, 하나의 작업을 CPU와 DMA 컨트롤러가 동시에 수행하지 않는다
  - 메모리(memory): 데이터나 명령어 등을 기록하는 기록 장치를 의미하며, 보통 RAM(Random Access Memory)를 메모리라고 부른다
  - 타이머(timer): 특정 프로그램에 시간 제한을 걸기 위해 사용된다
  - 디바스터 컨트롤러(device controller): I/O 디바이스와 연결되어 있는 작은 CPU를 의미하고, 각 디바이스에 대한 데이터를 임시로 저장하기 위한 버퍼도 존재한다


### 1. 메모리
- 메모리 계층
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/e10ea47b-e14c-4d73-9853-ee23f4644a59)
  - 레지스터: CPU 안에 있는 작은 메모리, 휘발성이 있고, 기억 용량이 가장 적다
  - 캐시(cache)
    - 빠른 장치와 느린 장치에서 속도 차이에 대한 병목 현상을 줄이기 위한 메모리로 휘발성이 있고 CPU(레지스터)와 메모리 사이에 위치한다
    - 시간 지역성(temporal locality, 계속 사용하는 for문의 변수 등)와 공간 지역성(spatial locality, 배열과 같은 연속된 공간 등)를 고려하여 자주 사용하는 데이터를 기반으로 설정해야 한다
    - 캐시 매핑
      - 캐시가 히트되기 위해 캐시에 데이터를 매핑하는 방법을 의미한다
      - 직접 매핑(directed mapping)은 메모리가 1~100, 캐시가 1~10이라면 1:1~10,2:11~20...과 같이 순서를 일치시켜 매핑하여 처리가 빠르지만 충돌이 자주 발생한다
      - 연관 매핑(associative mapping)은 순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑하여 충돌을 적지만 모든 블록을 탐색해야 해서 속도가 느리다
      - 집합 연관 매핑(set associative mapping)은 직접 매핑과 연관 매핑을 합쳐 놓은 것으로 순서는 일치시키지만 블록으로 나눠 그 안에는 연관 매핑을 한다
    - 웹 브라우저의 캐시
      - 쿠키: 만료기한이 있는 키-값 저장소로 다른 도메인에서 요청했을 때 자동으로 전송된다
      - 세션: 만료기한이 없는 키-값 저장소로 탭 단위로 스토리지를 생성하고 탭을 닫으면 데이터가 삭제된다
      - 로컬 스토리지: 만료기한이 없는 키-값 저장소로 도메인 단위로 저장되고 브라우저를 닫아도 유지된다
    - 데이터베이스의 캐시
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/c4bd9d94-032e-4d9f-b21f-dc6a24d74701)
  - 주기억장치: RAM을 가리키고 휘발성이 있다
  - 보조기억장치: HDD, SSH를 가리키고 비휘발성이고, 속도가 느린만큼 용량이 크다
- 가상 메모리(virtual memory)
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/99e9b538-0c0e-4d6b-b6c6-4564b214ad9c)
  - 메모리 관리 기법의 하나로 실제 메모리 자원을 추상화하여 사용자에게 매우 큰 메모리로 보이게 만드는 기법이다
  - 실제 메모리상에 있는 주소를 physical address 라고 하고 최소 크기의 단위는 프레임(frame)을 사용한다
  - 가상 메모리상에 있는 주소를 logical address 라고 하고 최소 크기 단위는 페이지(page)를 사용한다
  - 가상 주소는 메모리관리장치(MMU)에 의해 실제 주소로 변환되며 페이지 테이블(page table)에 가상 주소와 실제 주소가 매핑되어 있다
    - TLB(Translation Lookaside Buffer): 페이지 테이블에 있는 리스트를 보관하며 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시
  - 페이지 폴트(page fault)
    - 가상 메모리(프로세스의 주소 공간)에는 존재하지만 실제 메모리에 없는 데이터에 접근할 경우 발생
    - 스와핑(swapping): 페이지 폴트가 발생하여 메모리에서 당장 사용하지 않는 영역을 HDD로 옮기고 HDD의 일부분을 메모리처럼 불러와 사용하는 작업
    - 페이지 폴트 과정 
      1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩(trap)을 발생해서 운영체제에 알린다
      2. 운영체제는 CPU의 동작을 잠시 멈추고, 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인한다
      3. 가상 메모리에도 없다면 프로세스를 중단시키고 현재 물리 메모리에 비어 있는 프레임을 찾는다
      4. 빈 공간이 없다면 스와핑 시킨 후, 스와핑된 프레임에 해당 페이지를 로드하고 페이지 테이블을 최신화한다
      5. 중단되었던 CPU를 다시 시작한다
  - 쓰레싱(thrashing)
    - 메모리에 너무 많은 프로세스가 동시에 올라가서 메모리의 페이지 폴트율이 높아져 발생하는 컴퓨터의 심각한 성능 저하를 의미한다
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/72b129d6-a191-4925-b2e6-042ba2dcbe6e)
      - 쓰레싱이 발생하면 CPU 이용률이 낮아지고 운영체제는 CPU의 가용성을 높이기 위해 더 많은 프로세스를 메모리에 올리는 악순환이 발생한다
    - 해결 방법
      - 작업 세트(working set): 프로세스의 과거 사용 이력인 지역성(locality)을 통해 페이지 집합을 만들어서 미리 메모리에 로드한다. 미리 메모리에 로드하면 탐색에 드는 비용을 줄일 수 있다
      - PFF(Page Fault Frequency): 페이지 폴트 빈도의 상한선과 하한선을 만들어서 만약 상한선에 도달한다면 메모리 프레임을 늘리고 하한선에 도달하면 프레임을 줄인다
- 메모리 할당
  - 메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당한다
  - 메모리 공간에 연속적으로 할당할 수도 있고, 불연속적으로 할당할 수도 있으며, 현대 운영체제는 불연속 할당인 페이징 기법을 주로 사용한다
  - 용어 정리
    - 홀(hole): 할당할 수 잇는 비어 있는 메모리 공간을 의미한다
    - 내부 단편화(internal fragmentation): 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
    - 외부 단편화(external fragmentation): 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상 (100를 55,45로 나눴을 때 70의 프로그램을 들어가지 못한다)
    - 고정 분할 방식(fixed partition allocation)은 메모리를 미리 나누어 관리하는 방식이며 유연하지 않고 내부 단편화가 발생할 수 있다
    - 가변 분할 방식(variable partition allocation)은 매 시점 프로그램의 크기에 맞게 동적으로 할당하며, 내부 단편화는 없지만 외부 단편화는 존재한다
      - 최초 적합(first fit): 위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당한다
      - 최적 적합(best fit): 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당한다
      - 최악 적합(worst fit): 프로세스의 크기와 가장 많이 차이가 나는 홀에 할당한다
  - 할당 방법
    - 페이징(pageing)
      - 메모리를 동일한 크기의 페이지(보통 4KB)로 나누고 프로그램마다 페이지 테이블(page table)을 두어 메모리에 프로그램을 할당하는 방법
      - 홀의 크기가 균일하지 않은 문제는 없지만 주소 변환이 복잡하다
    - 세그멘테이션(segmentation)
      - 코드 영역, 데이터 영억, 스택 영역, 힙 영역 등의 의미가 있는 단위인 세그먼트(segment)로 메모리를 나누는 방법
      - 공유와 보안 측면에서는 장점을 가지지만 홀 크기가 균일하지 않은 단점이 있다
    - 페이지드 세그멘테이션(paged segmentation): 프로그램을 의미 단위인 세그먼트로 나눈 후 임의의 길이가 아닌 돌일한 크기의 페이지 단위로 나누는 방법
- 페이지 교체 알고리즘
  - 메모리가 한정되어 있기 때문에 스와핑이 발생할 경우 교체해야 하는 부분을 정하는 알고리즘
  - FIFO(First In First Out): 메모리에 가장 먼저 온 페이지를 먼저 교체하는 방법
  - LRU(Least Recently Used)
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/d699cc2e-6cb4-4dc6-828b-ca5e048c5dc6)
    - 참조가 가장 오래된 페이지를 바꾸는 방법이며 오래된 것을 파악하기 위해 페이지마다 계수기와 스택이 존재할 수 있다
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/7b1f85d0-e967-4392-a0b6-ea05f63cb25b)
    - 해시 테이블과 이중 연결 리스트로 구현할 수 있고, head에 가까운 node 일수록 가장 최근에 참조된 페이지, tail 에 가까운 node 일수록 가장 오랫동안 참조되지 않는 페이지
  - NUR(Not Used Recently)
    - ![image](https://github.com/kimho1wq/TIL/assets/15611500/a508a9e5-c220-44c1-9204-8b559df20e94)
    - clock 알고리즘이라고 하며 LRU를 근사한 알고리즘이지만 페이지의 참조 시점이 가장 오래되었다는 것은 보장하지 않는다
    - 최근 참조된 것은 1로 표시하고 아닌것은 0으로 표시한 후 시계 방향으로 돌면서 0을 찾아 교체하는 방법
  - LFU(Least Frequently Used): 가장 참조 횟수가 적은 페이지를 교체하는 방법


### 2. 프로세스와 스레드
- 프로그램의 컴파일 과정
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/4d897371-1ffc-4873-b7b4-c5d0da206698)
  - 전처리: 소스 코드의 주석을 제거하고 헤더 파일을 병합하여 매크로를 치환한다
  - 컴파일러: 오류 처리, 코드 최적화 작업을 하며 어셈블리어로 변환한다
  - 어셈블러: 컴파일된 어셈블리어는 목적 코드(object code)로 변환됩니다
  - 링커: 프로그램 내에 있는 라이브러리 함수 또는 다른 파일들과 목적 코드를 결합하여 실행 파일을 만든다
- 프로세스의 상태
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/e159cbd0-1d7f-47f4-988e-2f859689af0f)
  - 생성 상태(create): fork() 또는 exec() 함수를 통해 프로세스가 생성된 상태를 의미하며, 이때 PCB가 할당된다
  - 대기 상태(ready): CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태로, 메모리 공간이 충분하면 메모리를 할당받고 아니면 대기한다
  - 대기 중단 상태(ready suspended): 메모리 부족으로 일시 중단된 상태를 의미한다
  - 실행 상태(running): CPU 소유권과 메모리를 할당받고 명령(instruction)을 수행 중인 상태를 의미하고, 이를 CPU burst가 일어났다고 표현한다
  - 중단 상태(blocked): 인터럽트와 같은 어떤 이벤트가 발생한 이후 기다리며 프로레스가 차단된 상태를 의미한다
  - 일시 중단 상태(blocked suspended): 대기 중단 상태와 유사하고, 중단 상태에서 메모리 부족으로 일시 중단된 상태를 의미한다
- 프로세스의 메모리 구조
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/74840242-1d0e-4d19-b977-1008ad42d3f6)
  - 스택과 힙은 런타임 단계에서 메모리를 할당받는 동적 할당이며 데이터 영역과 코드 영역은 컴파일 단계에서 메모리를 할당하는 정적 할당이다
  - 스택은 지역변수, 매개변수, 실행되는 함수에서 생성된 변수의 메모리 영역이고, 힙은 동적으로 할당되는 변수의 메모리 영역이다
  - 데이터 영역은 BSS segment(Uninitialized Data)와 Data segement(Initialized Data), code/text segment로 나뉜다
    - bss segment는 전역 변수, static, const로 선언되어 있고 0으로 초기화된 변수 또는 초기화가 되어 있지 않은 변수들이 이 메모리 영역에 할당된다
    - data segment는 전역 변수, static, const로 선언되어 있고 0이 아닌 값으로 초기화된 변수가 이 메모리 영역에 할당된다
    - code/text segment는 실행 가능한 명령어(instruction)가 포함된 프로그램의 코드가 할당된다
  - segment 영역이 구분되는 이유는 code는 ROM에, bss는 RAM에, data는 ROM에 저장하고, 실행과 함께 RAM으로 불러와 사용하여 메모리 공간을 효율적으로 사용하기 위함이다
- PCB(Process Control Block)
  - 운영체제에서 프로세스에 대한 메타데이터를 저장한 데이터를 의미하며, 프로세스가 생성되면 운영체제는 PCB를 생성한다
  - 프로세스 스케줄링 상태, 프로세스 ID와 권한, 프로그램 카운터, CPU 레지스터와 스케줄링 정보 등
  - CPU가 해당 프로세스를 실행하기 위한 메타 정보들 컨텍스트(context)라고 하며 컨텍스트가 PCB에 저장되어 있다
- 컨텍스트 스위칭(context switching)
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/e69d4bc5-dfc4-4e3e-8324-668d0827a312)
  - 기존에 실행되던 프로세스를 중단하고 다른 프로세스로 교체하는 과정을 의미한다
  - 프로세스에 할당된 시간이 끝나거나 인터럽트에 의해 발생하며 PCB를 교환하는 과정을 의미한다
  - 스레드에서도 스위칭이 일어나며 스레드는 스택 영역을 제외한 모든 메모리를 공유하기 때문에 프로세스 스위칭보다 빠르다
- IPC(Inter Process Communication)
  - 프로세스끼리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘을 의미한다
  - 여러 개의 프로세스를 통해 동시에 두 가지 이상의 일을 수행하는 멀티프로세스는 IPC가 가능하다
  - IPC의 종류로는 공유 메모리, 파일, 소켓, 익명/명명 파이프, 메시지 큐 등이 있다
  - IPC는 메모리가 완전히 공유되는 스레드보다는 속도가 느리다
    - 공유 메모리(shared memory): 여러 프로세스가 접근 권한이 부여된 공유 메모리 블록을 통해 서로 통신하는 방법
    - 익명 파이프(unamed pipe): 프로세스 간에 FIFO 방식으로 데이터를 주고받으며, 단방향의 읽기 전용, 쓰기 전용 파이프를 만들어 통신하는 방법. 부모, 자식 프로세스 간에만 사용할 수 있으며 다른 네트워크 상에서는 사용이 불가하다
    - 명명 파이프(named pipe): 클라이언트/서버 통신을 위한 파이프 서버를 통해 통신하는 방법. 다른 네트워크상의 컴퓨터와도 통신할 수 있다
    - 메시지 큐(message queue): 메시지를 큐 형태로 관리하며, 커널에서 전역적으로 관리하며 사용이 쉽다
- 스레드와 멀티스레딩
  - ![image](https://github.com/kimho1wq/TIL/assets/15611500/623a58ad-37a0-45ad-835c-aa586796f747)
  - 스레드는 프로세스의 실행 가능한 가장 작은 단위로 프로세스는 여러개의 스레드를 가질 수 있다
  - 스레드는 코드, 데이터, 힙 영역을 공유하고, 그 영역은 각각 생성된다
  - 멀티스레딩은 프로세스 내 작업을 여러 개의 스레드로 처리하는 방법이며 빠른 속도와 동시성에도 큰 장점이 있지만, 한 스레드가 다른 스레드에 영향을 줄 수 있다는 단점도 있다
    - 동시성: 서로 독립적인 작업들을 작은 단위로 나누고, 동시에 실행되는 것처럼 보여주는 것
- 공유 자원과 임계 구역
  - 공유 자원(shared resource): 시스템 안에서 각 프로세스와 스레드가 함께 접근할 수 있는 자원 또는 변수를 의미한다
  - 경쟁 상태(race condition): 공유 자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황을 의미한다
  - 임계 구역(critical section): 둘 이상의 프로세스, 스레드가 공유 자원에 접근할 때 순서등의 이유로 결과가 달라지는 코드 영역을 의미한다
    - 임계 구역 해결 조건 3가지
      - 상호 배제(mutual exclusion): 한 프로세스가 임계 구역에 들어갔을 때 다른 프로세스는 들어갈 수 없다
      - 한정 대기(bounded waiting): 특정 프로세스가 영원히 임계 구역에 들어가지 못하면 안 된다. 즉, 틍정 프로세스가 임계구역에 진입하지 못하면 안된다
      - 진행 융통성(progress flexibility): 임계구역에 프로세스가 없다면 어떠한 프로세스라도 들어가서 자원을 활용할 수 있다. 즉, 두 프로세스가 자원을 번갈아 쓴다고 가정할 때 한 쪽에서 자원을 안쓰고 있다고해서 다른 한 쪽 프로세스가 자원을 쓰고싶어도 자신의 turn이 아니라고 기다리는 것은 효율적이지 못하다는 의미
    - 뮤텍스(mutex)
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/3c20ea10-331f-4609-872d-a9549bf945ba)
      - 프로세스나 스레드가 공유 자원을 lock()을 통해 점금 설정하고 사용한 후 unlock()을 통해 잠금 해제하는 객체
      - 0과 1의 두 가지 값만 가질 수 있는 바이너리 세마포어라고도 한다
    - 세마포어(semaphore)
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/5575b035-7db0-417d-8ca9-9564b7f434d4)
      - 일반화된 뮤텍스로 간단한 정수 값과 wait(또는 P) 함수와 signal(또는 V) 함수로 공유 자원에 대한 접근을 처리한다
      - wait()은 자신의 차례가 올 때까지 기다리는 함수이며, signal()은 다음 프로세스로 순서를 넘겨주는 함수이다
      - 세마포어에는 조건 변수가 없고 프로세스나 스레드가 세마포어 값을 수정할 때 다른 프로세스나 스레드가 동시에 세마포어 값을 수정할 수 없다
    - 모니터(monitor)
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/6b491919-4ad8-45c0-89e5-4559416c47b1)
      - 둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유 자원을 숨기고 해당 접근에 대해 인터페이스만 제공한다
      - 임계구역에 접근하고자 하는 프로세스는 직접 P()나 V()를 사용하지 않고 모니터에 작업 요청한다
      - 모니터는 요청받은 작업을 모니터 큐에 저장한 후 순서대로 처리하고 그 결과만 해당 프로세스에게 알려준다
- 교착 상태(Deadlock)
  - 두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태를 의미한다
  - 교착 상태의 원인
    - 상호 배제(mutual exclusion): 한 프로세스가 자원을 독점하고 있어서 다른 프로세스들의 접근이 불가능 하다
    - 점유 대기(hold and wait): 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상태이다
    - 비선점(no preemption): 다른 프로세스의 자원을 강제적으로 가져올 수 없다
    - 환형 대기(circular wait): 자원을 기다리는 프로세스 간의 사이클이 형성되어 있다
  - 교착 상태의 해결 방법
    1. 자원을 할당할 때 교착 상태의 원인인 4가지 조건이 성립되지 않도록 설계한다
    2. 프로세스 당 요청할 자원들의 최대치를 통해 자원 할당 가능 여부를 파악하는 은행원 알고리즘을 사용한다
    3. 탐지(detection) 및 복구(recovery): 교착 상태가 발생하면 사이클이 있는지 찾아보고 이에 관련된 프로세스를 한 개씩 지운다
    4. 무시(ignore): 교착 상태는 매우 드물게 일어나기 때문에 이를 처리하는 비용이 더 커서 교착 상태가 발생해면 사용자가 작업을 중단한다
    - 은행원 알고리즘(Banker's Algorithm)
      - 프로세스 시작시 자신이 필요한 각 자원의 최대(max) 개수를 미리 선언합니다
      - 각 프로세스에서 자원요청이 있을때 요청을 승인하면 시스템이 안전한 상태(safe state)로 유지되는 경우에만 자원을 할당합니다
      - 불안정 상태(unsafe state)가 예상되면 다른 프로세스가 끝날 때까지 대기를 합니다

### 3. CPU 스케줄링 알고리즘
- CPU 스케줄링 알고리즘에 따라 어떤 프로그램에 CPU 소유권을 줄지 결정하고, 프로세스에서 해야 하는 일을 스레드 단위로 CPU에 할당
- 스케줄링 알고리즘의 목표는 CPU 이용률은 높게, 시간당 최대한 많은 일을 수행하게, 준비 큐(ready queue)에 있는 프로세스는 적게, 응답 시간은 짧게 설정하는 것을 목표로 한다
- ![image](https://github.com/kimho1wq/TIL/assets/15611500/a2df598e-b582-4fc0-b9f1-432e191e3a4f)
  - 비선점형 방식(non-preemptive)
    - 프로세스가 스스로 CPU 소유권을 포기하는 방식으며, 강제로 프로세스를 중지하지 않는다
    - 컨텍스트 스위칭으로 인한 부하가 적은 방식이다
    - FCFS(First Come, First Served)
      - 가장 먼저 온 것을 가장 먼저 처리하는 알고리즘
      - 길게 수행되는 프로세스 때문에 준비 큐에서 오래 기다리는 현상(convoy effect, 호위 효과)이 발생할 수 있다
    - SJF(Shortest Job First)
      - 실행 시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘
      - 긴 시간을 가진 프로세스가 실행되지 않는 현상(starvation)이 발생할 수 있다
    - 우선순위
      - 기존 SJF에 우선순위를 부여하여 오래된 작업일수록 우선순위를 높이는 aging 방법을 적용한 알고리즘
  - 선점형 방식(preemptive)
    - 프로세스를 알고리즘에 의해 중단시키고 강제로 다른 프로세스에게 CPU 소유권을 할당하는 방식
    - RR(Round Robin)
      - 우선순위 스케줄링(priority scheduling)의 일종으로 각 프로세스는 동일한 할당 시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐의 뒤로 보내는 알고리즘
      - 할당 시간이 너무 크면 FCFS 알고리즘되고, 너무 짧으면 컨텍스트 스위칭의 오버헤드가 커진다
      - Q만큼의 할당 시간이 부여되었고 N개의 프로세스가 있다면 (N-1)*Q 시간이 지나면 다시 자기 차례가 된다
      - 일반적으로 전체 작업 시간은 길어지지만 평균 응답 시간이 짧아져서 현대 컴퓨터가 사용하는 알고리즘이다
    - SRF(Shortest Remaining time First)
      - SRF는 SJF 도중 중간에 더 짧은 작업이 들어오면 수행하던 프로세스를 중지시키고 해당 프로세스를 수행하는 알고리즘
      - SJF는 중간에 실행 시간이 더 짧은 작업이 들어와도 기존 짧은 작업을 모두 수행하고 그 다음 작업을 이어나간다
    - 다단계 큐
      - 우선순위에 따른 준비 큐를 여러 개 사용하고, 큐마다 RR이나 FCFS등 다른 스케줄링 알고리즘을 적용하는 알고리즘
      - 큐 간의 프로세스 이동이 안되므로 스케줄링 부담이 적지만 유연성은 떨어진다
      - ![image](https://github.com/kimho1wq/TIL/assets/15611500/c22898c3-1bd8-4ad7-841f-49569c500ad1)








                                               